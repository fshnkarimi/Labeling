{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPL_Original.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jR3SjOL7m0gJ",
        "DtJCTgyF6GB0",
        "HYI-eYOz3Sjz",
        "mleXosd_3hIk",
        "B_7_f2j30mBG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdNMIJ7waXgc"
      },
      "source": [
        "## Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i1q6_eOFCbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa674c8-cb9b-48ca-a081-bd45a476e163"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w90X-eo_FEDU"
      },
      "source": [
        "os.chdir('drive/My Drive/Colab Notebooks/Labeling')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR3SjOL7m0gJ"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wURP0Jxui8-d"
      },
      "source": [
        "# Import Libraries \n",
        "import itertools as itt\n",
        "import numbers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from abc import abstractmethod\n",
        "from typing import Iterable, Tuple, List\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import plotly.graph_objects as go\n",
        "import xgboost as xgb\n",
        "from prettytable import PrettyTable\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__9u9qrOj01l"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtJCTgyF6GB0"
      },
      "source": [
        "## Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqwGOVvDRqvH"
      },
      "source": [
        "# Labelling algorithm X is price and th is our threshould\n",
        "\n",
        "def labeling(X, th):\n",
        "    n = len(X)\n",
        "    y = np.array([0 for i in range(n)])\n",
        "    FP = X[0]\n",
        "    xh = X[0]\n",
        "    xl = X[0]\n",
        "    HT = 0\n",
        "    LT = 0\n",
        "    cid = 0\n",
        "    FP_N = 0\n",
        "    for i in range(n):\n",
        "        if(X[i] > FP + X[0]*th):\n",
        "            xh, HT, FP_N, cid  = X[i], i, i, 1\n",
        "            break\n",
        "        if(X[i] < FP - X[0]*th):\n",
        "            xh,HT,FP_N,cid  = X[i],i,i,-1\n",
        "            break\n",
        "    for i in range(FP_N+1,n):\n",
        "        if(cid > 0):\n",
        "            if(X[i]>xh):\n",
        "                xh, HT = X[i], i\n",
        "            if(X[i] < xh - xh * th and LT<= HT):\n",
        "                for j in range(n):\n",
        "                    if(j > LT and j <= HT):\n",
        "                        y[j] = 1\n",
        "                xl, LT, cid = X[i], i, -1\n",
        "        if(cid < 0):\n",
        "            if(X[i] < xl):\n",
        "                xl, LT = X[i], i\n",
        "            if(X[i] > xl + xl * th and HT <= LT):\n",
        "                for j in range(n):\n",
        "                    if(j > HT and j <= LT):\n",
        "                        y[j] = 0\n",
        "                xh, HT, cid = X[i], i, 1\n",
        "    return y\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDOBqAAqdWXr"
      },
      "source": [
        "# Implement Cross-validation methods\n",
        "\n",
        "class BaseTimeSeriesCrossValidator:\n",
        "    \"\"\"\n",
        "    Abstract class for time series cross-validation.\n",
        "    Time series cross-validation requires each sample has a prediction time pred_time, at which the features are used to\n",
        "    predict the response, and an evaluation time eval_time, at which the response is known and the error can be\n",
        "    computed. Importantly, it means that unlike in standard sklearn cross-validation, the samples X, response y,\n",
        "    pred_times and eval_times must all be pandas dataframe/series having the same index. It is also assumed that the\n",
        "    samples are time-ordered with respect to the prediction time (i.e. pred_times is non-decreasing).\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_splits : int, default=10\n",
        "        Number of folds. Must be at least 2.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_splits=10):\n",
        "        if not isinstance(n_splits, numbers.Integral):\n",
        "            raise ValueError(f\"The number of folds must be of Integral type. {n_splits} of type {type(n_splits)}\"\n",
        "                             f\" was passed.\")\n",
        "        n_splits = int(n_splits)\n",
        "        if n_splits <= 1:\n",
        "            raise ValueError(f\"K-fold cross-validation requires at least one train/test split by setting n_splits = 2 \"\n",
        "                             f\"or more, got n_splits = {n_splits}.\")\n",
        "        self.n_splits = n_splits\n",
        "        self.pred_times = None\n",
        "        self.eval_times = None\n",
        "        self.indices = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def split(self, X: pd.DataFrame, y: pd.Series = None,\n",
        "              pred_times: pd.Series = None, eval_times: pd.Series = None):\n",
        "        if not isinstance(X, pd.DataFrame) and not isinstance(X, pd.Series):\n",
        "            raise ValueError('X should be a pandas DataFrame/Series.')\n",
        "        if not isinstance(y, pd.Series) and y is not None:\n",
        "            raise ValueError('y should be a pandas Series.')\n",
        "        if not isinstance(pred_times, pd.Series):\n",
        "            raise ValueError('pred_times should be a pandas Series.')\n",
        "        if not isinstance(eval_times, pd.Series):\n",
        "            raise ValueError('eval_times should be a pandas Series.')\n",
        "        if y is not None and (X.index == y.index).sum() != len(y):\n",
        "            raise ValueError('X and y must have the same index')\n",
        "        if (X.index == pred_times.index).sum() != len(pred_times):\n",
        "            raise ValueError('X and pred_times must have the same index')\n",
        "        if (X.index == eval_times.index).sum() != len(eval_times):\n",
        "            raise ValueError('X and eval_times must have the same index')\n",
        "\n",
        "        self.pred_times = pred_times\n",
        "        self.eval_times = eval_times\n",
        "        self.indices = np.arange(X.shape[0])\n",
        "        \n",
        "class CombPurgedKFoldCV(BaseTimeSeriesCrossValidator):\n",
        "    \"\"\"\n",
        "    Purged and embargoed combinatorial cross-validation\n",
        "    As described in Advances in financial machine learning, Marcos Lopez de Prado, 2018.\n",
        "    The samples are decomposed into n_splits folds containing equal numbers of samples, without shuffling. In each cross\n",
        "    validation round, n_test_splits folds are used as the test set, while the other folds are used as the train set.\n",
        "    There are as many rounds as n_test_splits folds among the n_splits folds.\n",
        "    Each sample should be tagged with a prediction time pred_time and an evaluation time eval_time. The split is such\n",
        "    that the intervals [pred_times, eval_times] associated to samples in the train and test set do not overlap. (The\n",
        "    overlapping samples are dropped.) In addition, an \"embargo\" period is defined, giving the minimal time between an\n",
        "    evaluation time in the test set and a prediction time in the training set. This is to avoid, in the presence of\n",
        "    temporal correlation, a contamination of the test set by the train set.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_splits : int, default=10\n",
        "        Number of folds. Must be at least 2.\n",
        "    n_test_splits : int, default=2\n",
        "        Number of folds used in the test set. Must be at least 1.\n",
        "    embargo_td : pd.Timedelta, default=0\n",
        "        Embargo period (see explanations above).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_splits=10, n_test_splits=2, embargo_td=0):\n",
        "        super().__init__(n_splits)\n",
        "        if not isinstance(n_test_splits, numbers.Integral):\n",
        "            raise ValueError(f\"The number of test folds must be of Integral type. {n_test_splits} of type \"\n",
        "                             f\"{type(n_test_splits)} was passed.\")\n",
        "        n_test_splits = int(n_test_splits)\n",
        "        if n_test_splits <= 0 or n_test_splits > self.n_splits - 1:\n",
        "            raise ValueError(f\"K-fold cross-validation requires at least one train/test split by setting \"\n",
        "                             f\"n_test_splits between 1 and n_splits - 1, got n_test_splits = {n_test_splits}.\")\n",
        "        self.n_test_splits = n_test_splits\n",
        "\n",
        "        if embargo_td < 0:\n",
        "            raise ValueError(f\"The embargo time should be positive, got embargo = {embargo_td}.\")\n",
        "        self.embargo_td = embargo_td\n",
        "\n",
        "    def split(self, X: pd.DataFrame, y: pd.Series = None,\n",
        "              pred_times: pd.Series = None, eval_times: pd.Series = None) -> Iterable[Tuple[np.ndarray, np.ndarray]]:\n",
        "        \"\"\"\n",
        "        Yield the indices of the train and test sets.\n",
        "        Although the samples are passed in the form of a pandas dataframe, the indices returned are position indices,\n",
        "        not labels.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame, shape (n_samples, n_features), required\n",
        "            Samples. Only used to extract n_samples.\n",
        "        y : pd.Series, not used, inherited from _BaseKFold\n",
        "        pred_times : pd.Series, shape (n_samples,), required\n",
        "            Times at which predictions are made. pred_times.index has to coincide with X.index.\n",
        "        eval_times : pd.Series, shape (n_samples,), required\n",
        "            Times at which the response becomes available and the error can be computed. eval_times.index has to\n",
        "            coincide with X.index.\n",
        "        Returns\n",
        "        -------\n",
        "        train_indices: np.ndarray\n",
        "            A numpy array containing all the indices in the train set.\n",
        "        test_indices : np.ndarray\n",
        "            A numpy array containing all the indices in the test set.\n",
        "        \"\"\"\n",
        "        super().split(X, y, pred_times, eval_times)\n",
        "\n",
        "        # Fold boundaries\n",
        "        fold_bounds = [(fold[0], fold[-1] + 1) for fold in np.array_split(self.indices, self.n_splits)]\n",
        "        # List of all combinations of n_test_splits folds selected to become test sets\n",
        "        selected_fold_bounds = list(itt.combinations(fold_bounds, self.n_test_splits))\n",
        "        \n",
        "        # In order for the first round to have its whole test set at the end of the dataset\n",
        "        selected_fold_bounds.reverse()\n",
        "\n",
        "        for fold_bound_list in selected_fold_bounds:\n",
        "            # Computes the bounds of the test set, and the corresponding indices\n",
        "            test_fold_bounds, test_indices = self.compute_test_set(fold_bound_list)\n",
        "            # Computes the train set indices\n",
        "            train_indices = self.compute_train_set(test_fold_bounds, test_indices)\n",
        "\n",
        "            yield train_indices, test_indices\n",
        "\n",
        "    def compute_train_set(self, test_fold_bounds: List[Tuple[int, int]], test_indices: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute the position indices of samples in the train set.\n",
        "        Parameters\n",
        "        ----------\n",
        "        test_fold_bounds : List of tuples of position indices\n",
        "            Each tuple records the bounds of a block of indices in the test set.\n",
        "        test_indices : np.ndarray\n",
        "            A numpy array containing all the indices in the test set.\n",
        "        Returns\n",
        "        -------\n",
        "        train_indices: np.ndarray\n",
        "            A numpy array containing all the indices in the train set.\n",
        "        \"\"\"\n",
        "        # As a first approximation, the train set is the complement of the test set\n",
        "        train_indices = np.setdiff1d(self.indices, test_indices)\n",
        "        # But we now have to purge and embargo\n",
        "        for test_fold_start, test_fold_end in test_fold_bounds:\n",
        "            # Purge\n",
        "            train_indices = purge(self, train_indices, test_fold_start, test_fold_end)\n",
        "            # Embargo\n",
        "            train_indices = embargo(self, train_indices, test_indices, test_fold_end)\n",
        "        return train_indices\n",
        "\n",
        "    def compute_test_set(self, fold_bound_list: List[Tuple[int, int]]) -> Tuple[List[Tuple[int, int]], np.ndarray]:\n",
        "        \"\"\"\n",
        "        Compute the indices of the samples in the test set.\n",
        "        Parameters\n",
        "        ----------\n",
        "        fold_bound_list: List of tuples of position indices\n",
        "            Each tuple records the bounds of the folds belonging to the test set.\n",
        "        Returns\n",
        "        -------\n",
        "        test_fold_bounds: List of tuples of position indices\n",
        "            Like fold_bound_list, but with the neighboring folds in the test set merged.\n",
        "        test_indices: np.ndarray\n",
        "            A numpy array containing the test indices.\n",
        "        \"\"\"\n",
        "        test_indices = np.empty(0)\n",
        "        test_fold_bounds = []\n",
        "        for fold_start, fold_end in fold_bound_list:\n",
        "            # Records the boundaries of the current test split\n",
        "            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n",
        "                test_fold_bounds.append((fold_start, fold_end))\n",
        "            # If the current test split is contiguous to the previous one, simply updates the endpoint\n",
        "            elif fold_start == test_fold_bounds[-1][-1]:\n",
        "                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n",
        "            test_indices = np.union1d(test_indices, self.indices[fold_start:fold_end]).astype(int)\n",
        "        return test_fold_bounds, test_indices\n",
        "\n",
        "\n",
        "def embargo(cv: BaseTimeSeriesCrossValidator, train_indices: np.ndarray,\n",
        "            test_indices: np.ndarray, test_fold_end: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Apply the embargo procedure to part of the train set.\n",
        "    This amounts to dropping the train set samples whose prediction time occurs within self.embargo_dt of the test\n",
        "    set sample evaluation times. This method applies the embargo only to the part of the training set immediately\n",
        "    following the end of the test set determined by test_fold_end.\n",
        "    Parameters\n",
        "    ----------\n",
        "    cv: Cross-validation class\n",
        "        Needs to have the attributes cv.pred_times, cv.eval_times, cv.embargo_dt and cv.indices.\n",
        "    train_indices: np.ndarray\n",
        "        A numpy array containing all the indices of the samples currently included in the train set.\n",
        "    test_indices : np.ndarray\n",
        "        A numpy array containing all the indices of the samples in the test set.\n",
        "    test_fold_end : int\n",
        "        Index corresponding to the end of a test set block.\n",
        "    Returns\n",
        "    -------\n",
        "    train_indices: np.ndarray\n",
        "        The same array, with the indices subject to embargo removed.\n",
        "    \"\"\"\n",
        "    if not hasattr(cv, 'embargo_td'):\n",
        "        raise ValueError(\"The passed cross-validation object should have a member cv.embargo_td defining the embargo\"\n",
        "                         \"time.\")\n",
        "    last_test_eval_time = cv.eval_times.iloc[cv.indices[:test_fold_end]].max()\n",
        "    min_train_index = len(cv.pred_times[cv.pred_times <= last_test_eval_time + cv.embargo_td])\n",
        "    if min_train_index < cv.indices.shape[0]:\n",
        "        allowed_indices = np.concatenate((cv.indices[:test_fold_end], cv.indices[min_train_index:]))\n",
        "        train_indices = np.intersect1d(train_indices, allowed_indices)\n",
        "    return train_indices\n",
        "\n",
        "\n",
        "def purge(cv: BaseTimeSeriesCrossValidator, train_indices: np.ndarray,\n",
        "          test_fold_start: int, test_fold_end: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Purge part of the train set.\n",
        "    Given a left boundary index test_fold_start of the test set, this method removes from the train set all the\n",
        "    samples whose evaluation time is posterior to the prediction time of the first test sample after the boundary.\n",
        "    Parameters\n",
        "    ----------\n",
        "    cv: Cross-validation class\n",
        "        Needs to have the attributes cv.pred_times, cv.eval_times and cv.indices.\n",
        "    train_indices: np.ndarray\n",
        "        A numpy array containing all the indices of the samples currently included in the train set.\n",
        "    test_fold_start : int\n",
        "        Index corresponding to the start of a test set block.\n",
        "    test_fold_end : int\n",
        "        Index corresponding to the end of the same test set block.\n",
        "    Returns\n",
        "    -------\n",
        "    train_indices: np.ndarray\n",
        "        A numpy array containing the train indices purged at test_fold_start.\n",
        "    \"\"\"\n",
        "    time_test_fold_start = cv.pred_times.iloc[test_fold_start]\n",
        "    # The train indices before the start of the test fold, purged.\n",
        "    train_indices_1 = np.intersect1d(train_indices, cv.indices[cv.eval_times < time_test_fold_start])\n",
        "    # The train indices after the end of the test fold.\n",
        "    train_indices_2 = np.intersect1d(train_indices, cv.indices[test_fold_end:])\n",
        "\n",
        "    return np.concatenate((train_indices_1, train_indices_2))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7Vd77V19PT"
      },
      "source": [
        "def get_metrics(label, y_pred, show_results=False):\n",
        "  \n",
        "  results = []\n",
        "  results.append(metrics.accuracy_score(label, y_pred))\n",
        "  results.append(metrics.precision_score(label, y_pred))\n",
        "  results.append(metrics.recall_score(label, y_pred))\n",
        "  results.append(metrics.f1_score(label, y_pred))\n",
        "\n",
        "  # I changed floating point precision to 2 digits from original 6 digits set by the team.\n",
        "  if show_results:\n",
        "    print(\"Accuracy:{:.2f}\".format(metrics.accuracy_score(label, y_pred)))\n",
        "    print(\"Precision:{:.2f}\".format(metrics.precision_score(label, y_pred)))\n",
        "    print(\"Recall:{:.2f}\".format(metrics.recall_score(label, y_pred)))\n",
        "    print(\"F1 score:{:.2f}\".format(metrics.f1_score(label, y_pred)))\n",
        "    \n",
        "  return results"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzChyAFBka7-"
      },
      "source": [
        "def data_pre1d(df, index, label, step_size):\n",
        "  x = np.array([df[i + step_size - 1:i+step_size*11:step_size] for i in index if (i-1 + 11*step_size) in index])\n",
        "  y = np.array([label[i-1 + 11*step_size] for i in index if (i-1 + 11*step_size) in index])\n",
        "  x = x / np.mean(x,axis = 1).reshape((len(x), 1))\n",
        "  x = x - np.ones((len(x), 1))\n",
        "  x = x.reshape(x.shape[0], x.shape[1], 1)\n",
        "  y = (y + 1) // 2\n",
        "  return x, y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YkBltamjYNt"
      },
      "source": [
        "def signal_to_noise(a, axis=0, ddof=0):\n",
        "    \"\"\"\n",
        "    The signal-to-noise ratio of the input data.\n",
        "    Returns the signal-to-noise ratio of `a`, here defined as the mean\n",
        "    divided by the standard deviation.\n",
        "    Parameters\n",
        "    ----------\n",
        "    a : array_like\n",
        "        An array_like object containing the sample data.\n",
        "    axis : int or None, optional\n",
        "        Axis along which to operate. Default is 0. If None, compute over\n",
        "        the whole array `a`.\n",
        "    ddof : int, optional\n",
        "        Degrees of freedom correction for standard deviation. Default is 0.\n",
        "    Returns\n",
        "    -------\n",
        "    s2n : ndarray\n",
        "        The mean to standard deviation ratio(s) along `axis`, or 0 where the\n",
        "        standard deviation is 0.\n",
        "    \"\"\"\n",
        "    a = np.asanyarray(a)\n",
        "    m = a.mean(axis)\n",
        "    sd = a.std(axis=axis, ddof=ddof)\n",
        "    s2n = np.where(sd == 0, 0, m/sd)\n",
        "    return float(s2n)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USyqsL1Mp9YE"
      },
      "source": [
        "def find_k(s2n):\n",
        "  if s2n < 2.5:\n",
        "    return 75\n",
        "  if s2n < 3:\n",
        "    return 40\n",
        "  if s2n < 3.5:\n",
        "    return 20\n",
        "  else:\n",
        "    return 5  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYI-eYOz3Sjz"
      },
      "source": [
        "## Denoise Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfyQgHA1jwWM"
      },
      "source": [
        "def denoise_data(df, col_name, k=100):\n",
        "  clf = KNeighborsRegressor(n_neighbors=k, weights='uniform')\n",
        "  clf.fit(df.index.values[:, np.newaxis], df[\"<CLOSE>\"])\n",
        "  y_pred = clf.predict(df.index.values[:, np.newaxis])  \n",
        "  reverse_pred = y_pred[::-1]\n",
        "  ax = pd.Series(df[\"<CLOSE>\"]).plot(color='lightgray')\n",
        "  pd.Series(y_pred).plot(color='black', ax=ax, figsize=(12, 8))\n",
        "  plt.title(\"Denoising data\")\n",
        "  df['<D_CLOSE>'] = y_pred\n",
        "  return df"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrMsJOy5XNpV"
      },
      "source": [
        "def denoise_data_EWMA(df, col_name, span=10):\n",
        "  df['<D_CLOSE>'] = df[col_name].ewm(span=span, adjust=False).mean()\n",
        "  ax = pd.Series(df[col_name]).plot(color='lightgray')\n",
        "  pd.Series(df['<D_CLOSE>']).plot(color='black', ax=ax, figsize=(12, 8))\n",
        "  plt.title(\"Denoising data\")\n",
        "  return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mleXosd_3hIk"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rQBNo1O7f2c"
      },
      "source": [
        "def visualize(dfs, col_name, date, th, start, end):\n",
        "  label = labeling(dfs[col_name], th)\n",
        "  # date_col = dfs[date].astype(str).str[:4]\n",
        "  date_col = dfs[date]\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=date_col[start:end], y=dfs[col_name][start:end]))\n",
        "  fig.show()\n",
        "  fig = go.Figure([go.Scatter(x=date_col[start:end], y=label[start:end])])\n",
        "  fig.show() "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKNlyB6Va1lF"
      },
      "source": [
        "## Train_data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEk0ml6W2quS"
      },
      "source": [
        "# Define a class for training models\n",
        "\n",
        "class Train_data():\n",
        "  def __init__(self, data,  train_start, train_end, test_end):\n",
        "    self.train_start = train_start\n",
        "    self.train_end = train_end\n",
        "    self.test_end = test_end \n",
        "    self.data = data\n",
        "    self.train_data = pd.Series(np.array(data[train_start:train_end]))\n",
        "    self.train_label = None\n",
        "    self.test_data = pd.Series(np.array(data[train_end:test_end]))\n",
        "    self.test_label = None\n",
        "    self.splits = []\n",
        "    self.X_train  = []\n",
        "    self.y_train = []\n",
        "    self.X_test  = []\n",
        "    self.y_test = []\n",
        "    self.GRU_beta_result = None\n",
        "    self.LSTM_beta_result = None\n",
        "    self.XGboost_beta_result = None\n",
        "    self.SVM_beta_result = None\n",
        "    self.Logreg_beta_result = None\n",
        "    self.GRU_result = None\n",
        "    self.LSTM_result = None\n",
        "    self.XGboost_result = None\n",
        "    self.SVM_result = None\n",
        "    self.Logreg_result = None\n",
        "    self.GRU_beta_predict = None\n",
        "    self.LSTM_beta_predict = None\n",
        "    self.XGboost_beta_predict = None\n",
        "    self.SVM_beta_predict = None\n",
        "    self.Logreg_beta_predict = None\n",
        "    self.GRU_predict = None\n",
        "    self.LSTM_predict = None\n",
        "    self.XGboost_predict = None\n",
        "    self.SVM_predict = None\n",
        "    self.Logreg_predict = None\n",
        "\n",
        "  def set_threshold(self, th):\n",
        "    label  = labeling(self.data, th)\n",
        "    self.train_label = pd.Series(np.array(label[self.train_start:self.train_end]))\n",
        "    self.test_label = pd.Series(np.array(label[self.train_end:self.test_end]))\n",
        "\n",
        "  def K_fold_purged(self, num_split, num_test, time_gaps, emb=0, purging=True):\n",
        "    n_splits = num_split\n",
        "    n_test_splits = num_test\n",
        "    time_gap = time_gaps\n",
        "    embargo_td = emb\n",
        "    t1_ = self.train_data.index\n",
        "    t1 = pd.Series(t1_).shift(time_gap).fillna(0).astype(int)\n",
        "    t2 = pd.Series(t1_).shift(-time_gap).fillna(1e12).astype(int)\n",
        "    \n",
        "    if purging:\n",
        "      cpkf = CombPurgedKFoldCV(n_splits=n_splits, n_test_splits=n_test_splits, embargo_td=embargo_td)\n",
        "      comb_purged_splits = list(cpkf.split(self.train_data, pred_times=t1, eval_times=t2))\n",
        "      self.splits = comb_purged_splits\n",
        "    \n",
        "    else:\n",
        "      cvts = TimeSeriesSplit(n_splits=n_splits)\n",
        "      cvts_splits = list(cvts.split(self.train_data))\n",
        "      self.splits = cvts_splits\n",
        "\n",
        "\n",
        "  def SVM(self, beta):\n",
        "\n",
        "    Xtrain = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1])\n",
        "    Xtest = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1])\n",
        "    clf = SVC(C=1)\n",
        "    clf.fit( Xtrain,self.y_train)\n",
        "    y_pred = clf.predict(Xtest)\n",
        "    if beta : \n",
        "      self.SVM_beta_result  =  get_metrics(self.y_test, y_pred,0)\n",
        "      self.SVM_beta_predict = y_pred    \n",
        "    else:\n",
        "      self.SVM_result  =  get_metrics(self.y_test,y_pred,0)\n",
        "      self.SVM_predict = y_pred\n",
        "    \n",
        "\n",
        "  def log_reg(self, beta):\n",
        "    \n",
        "    Xtrain = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1])\n",
        "    Xtest = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1])\n",
        "    clf = LogisticRegression(C=10, penalty=\"l2\")\n",
        "    clf.fit( Xtrain,self.y_train)\n",
        "    y_pred = clf.predict(Xtest)\n",
        "    if beta: \n",
        "      self.Logreg_beta_result  =  get_metrics(self.y_test,y_pred,0)\n",
        "      self.Logreg_beta_predict = y_pred\n",
        "    else:\n",
        "      self.Logreg_result  =  get_metrics(self.y_test,y_pred,0)\n",
        "      self.Logreg_predict = y_pred\n",
        "    \n",
        "    \n",
        "\n",
        "  def data_preprocess(self, step_size):  \n",
        "    self.X_train, self.y_train = data_pre1d(self.train_data, self.train_data.index, self.train_label,step_size)\n",
        "    self.X_test, self.y_test = data_pre1d(self.test_data, self.test_data.index, self.test_label,step_size)\n",
        "    \n",
        "\n",
        "  def LSTM(self, epoch, layer_size, window_size, lr, beta):\n",
        "    #with tf.device('/device:GPU:0'):\n",
        "      model=Sequential()\n",
        "      model.add(tf.keras.layers.LSTM(layer_size,return_sequences=True,input_shape=(window_size,1)))\n",
        "      model.add(Dropout(0.4))\n",
        "      model.add(tf.keras.layers.LSTM(layer_size))\n",
        "      model.add(Dropout(0.4))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "      opt = tf.keras.optimizers.Adam(beta_1=0.9,beta_2=0.999,learning_rate=lr)\n",
        "      model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
        "      \n",
        "      if beta:\n",
        "        print(f'start lstm beta training...\\n')\n",
        "        model.fit(self.X_train,self.y_train,validation_data=(self.X_test, self.y_test),epochs=epoch,batch_size=16,verbose=1)\n",
        "        y_pred = model.predict(self.X_test)\n",
        "        y_pred = np.array([1 if y >=0.5 else 0 for y in y_pred])\n",
        "        self.LSTM_beta_result = get_metrics(self.y_test, y_pred, False)\n",
        "        self.LSTM_beta_predict = y_pred\n",
        "      else:\n",
        "        print(f'start lstm training...\\n')\n",
        "        model.fit(self.X_train,self.y_train,validation_data=(self.X_test, self.y_test),epochs=epoch,batch_size=16,verbose=1)\n",
        "        y_pred = model.predict(self.X_test)\n",
        "        y_pred = np.array([1 if y >=0.5 else 0 for y in y_pred])\n",
        "        self.LSTM_result = get_metrics(self.y_test, y_pred, False)\n",
        "        self.LSTM_predict = y_pred\n",
        "      \n",
        "      print('end training. \\n')\n",
        "\n",
        "  def GRU(self, epoch, layer_size, window_size, lr, beta):\n",
        "    #with tf.device('/device:GPU:0'):\n",
        "      model=Sequential()\n",
        "      model.add(tf.keras.layers.GRU(layer_size,return_sequences=True,input_shape=(window_size,1)))\n",
        "      model.add(Dropout(0.4))\n",
        "      model.add(tf.keras.layers.GRU(layer_size))\n",
        "      model.add(Dropout(0.4))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "      opt = tf.keras.optimizers.Adam(beta_1=0.9,beta_2=0.999,learning_rate=lr)\n",
        "      model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "      if beta:\n",
        "        print('start gru beta training...\\n')\n",
        "        model.fit(self.X_train,self.y_train,validation_data=(self.X_test,self.y_test),epochs=epoch,batch_size=16,verbose=1)\n",
        "        y_pred = model.predict(self.X_test)\n",
        "        y_pred = np.array([1 if y >=0.5 else 0 for y in y_pred])\n",
        "        self.GRU_beta_result = get_metrics(self.y_test,y_pred,False)\n",
        "        self.GRU_beta_predict = y_pred\n",
        "      else:\n",
        "        print('start gru training...\\n')\n",
        "        model.fit(self.X_train,self.y_train,validation_data=(self.X_test,self.y_test),epochs=epoch,batch_size=16,verbose=1)\n",
        "        y_pred = model.predict(self.X_test)\n",
        "        y_pred = np.array([1 if y >=0.5 else 0 for y in y_pred])\n",
        "        self.GRU_result = get_metrics(self.y_test,y_pred,False)\n",
        "        self.GRU_predict = y_pred\n",
        "\n",
        "      print('end training. \\n')\n",
        "\n",
        "  def XGboost(self,es,beta):\n",
        "    Xtrain = self.X_train.reshape(self.X_train.shape[0],self.X_train.shape[1])\n",
        "    Xtest = self.X_test.reshape(self.X_test.shape[0],self.X_test.shape[1])\n",
        "    # XGBoost classifier with Early-stopping\n",
        "    clf = xgb.XGBClassifier(n_jobs=1)\n",
        "    if beta:\n",
        "      print('start xgboost beta training...\\n')\n",
        "      clf.fit(Xtrain, self.y_train, early_stopping_rounds=es, eval_metric=\"auc\",eval_set=[(Xtest, self.y_test)])\n",
        "      y_pred = clf.predict(Xtest)\n",
        "      self.XGboost_beta_result = get_metrics(self.y_test,y_pred,False)\n",
        "      self.XGboost_beta_predict = y_pred\n",
        "    else:\n",
        "      print('start xgboost training...\\n')\n",
        "      clf.fit(Xtrain, self.y_train, early_stopping_rounds=es, eval_metric=\"auc\",eval_set=[(Xtest, self.y_test)])\n",
        "      y_pred = clf.predict(Xtest)\n",
        "      self.XGboost_result = get_metrics(self.y_test,y_pred,False)\n",
        "      self.XGboost_predict = y_pred\n",
        "\n",
        "    print('end training. \\n')\n",
        "\n",
        "\n",
        "  def table(self, th = 0.1):\n",
        "    x = PrettyTable()\n",
        "    x.field_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 score\"]\n",
        "    self.LSTM_result.insert(0,\"LSTM \"+str(th))\n",
        "    self.GRU_result.insert(0,\"GRU \"+str(th))\n",
        "    self.XGboost_result.insert(0,\"XGBoost \"+str(th))\n",
        "    self.Logreg_result.insert(0,\"Logreg \"+str(th))\n",
        "    self.SVM_result.insert(0,\"SVM \"+str(th))\n",
        "    self.LSTM_beta_result.insert(0,\"LSTM beta \"+str(th))\n",
        "    self.GRU_beta_result.insert(0,\"GRU beta \"+str(th))\n",
        "    self.XGboost_beta_result.insert(0,\"XGBoost beta \"+str(th))\n",
        "    self.Logreg_beta_result.insert(0,\"logreg beta \"+str(th))\n",
        "    self.SVM_beta_result.insert(0,\"svm beta \"+str(th))\n",
        "    x.add_row(self.LSTM_result)\n",
        "    x.add_row(self.GRU_result)\n",
        "    x.add_row(self.XGboost_result)\n",
        "    x.add_row(self.Logreg_result)\n",
        "    x.add_row(self.SVM_result)\n",
        "    x.add_row(self.LSTM_beta_result)\n",
        "    x.add_row(self.GRU_beta_result)\n",
        "    x.add_row(self.XGboost_beta_result)\n",
        "    x.add_row(self.Logreg_beta_result)\n",
        "    x.add_row(self.SVM_beta_result)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def write_table(self, th=0.1):\n",
        "\n",
        "    self.LSTM_result.insert(0,\"LSTM \"+str(th))\n",
        "    self.GRU_result.insert(0,\"GRU \"+str(th))\n",
        "    self.XGboost_result.insert(0,\"XGBoost \"+str(th))\n",
        "    self.Logreg_result.insert(0,\"Logreg \"+str(th))\n",
        "    self.SVM_result.insert(0,\"SVM \"+str(th))\n",
        "    self.LSTM_beta_result.insert(0,\"LSTM beta \"+str(th))\n",
        "    self.GRU_beta_result.insert(0,\"GRU beta \"+str(th))\n",
        "    self.XGboost_beta_result.insert(0,\"XGBoost beta \"+str(th))\n",
        "    self.Logreg_beta_result.insert(0,\"logreg beta \"+str(th))\n",
        "    self.SVM_beta_result.insert(0,\"svm beta \"+str(th))\n",
        "\n",
        "    methods = ['LSTM', 'GRU', 'XGboost', 'Logreg', 'SVM']\n",
        "    beta = ['','_beta']\n",
        "    colnames = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 score\"]\n",
        "    data  = []\n",
        "    for b in beta:\n",
        "      for method in methods:\n",
        "        XX = method + b + '_result'\n",
        "        X = getattr(self, XX)\n",
        "        data.append([X[0], round(X[1],2), round(X[2],2), round(X[3],2), round(X[4],2)])\n",
        "    table_df = pd.DataFrame(data = data, columns=colnames)\n",
        "    print(table_df)\n",
        "    #table_df.to_csv('Results/classification/'+'AMD'+'.csv')\n",
        "\n",
        "  \n",
        "  def train_models(self, best_parameters, step_sizes=4, th = 0.1):\n",
        "\n",
        "    lstm_epoch = best_parameters[0]\n",
        "    lstm_layer = best_parameters[1]\n",
        "    lstm_lr = best_parameters[2]\n",
        "    gru_epoch = best_parameters[3]\n",
        "    gru_layer = best_parameters[4]\n",
        "    gru_lr = best_parameters[5]\n",
        "\n",
        "    self.data_preprocess(step_size=1)\n",
        "    self.LSTM(lstm_epoch, lstm_layer, 11, lstm_lr, False)\n",
        "    self.GRU(gru_epoch, gru_layer, 11, gru_lr, False)\n",
        "    self.XGboost(50, False)\n",
        "    self.SVM(False)\n",
        "    self.log_reg(False)\n",
        "\n",
        "    self.data_preprocess(step_size=step_sizes)\n",
        "    self.LSTM(lstm_epoch,lstm_layer,11,lstm_lr,True)\n",
        "    self.GRU(gru_epoch,gru_layer,11,gru_lr,True)\n",
        "    self.XGboost(50,True)\n",
        "    self.SVM(True)\n",
        "    self.log_reg(True)\n",
        "\n",
        "    \n",
        "    #print(self.table(th = th))\n",
        "    self.write_table(th=th)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFtt88V5aqSl"
      },
      "source": [
        "## final_result()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur-dIbFYaJXc"
      },
      "source": [
        "# Default best parameters\n",
        "\n",
        "\n",
        "default_best_param = [5, 10, 0.01, 5, 10, 0.01]\n",
        "\n",
        "def final_result(historical, name, best_param=default_best_param, step_sizes=4, th=0.1):\n",
        "  historical.train_models(best_param, step_sizes, th=th)\n",
        "  results = []\n",
        "  results.append(historical.LSTM_result)\n",
        "  results.append(historical.GRU_result)\n",
        "  results.append(historical.XGboost_result)\n",
        "  results.append(historical.Logreg_result)\n",
        "  results.append(historical.SVM_result)\n",
        "  results.append(historical.LSTM_beta_result)\n",
        "  results.append(historical.GRU_beta_result)\n",
        "  results.append(historical.XGboost_beta_result)\n",
        "  results.append(historical.Logreg_beta_result)\n",
        "  results.append(historical.SVM_beta_result)\n",
        "  colnames = ['Name', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "  Data = []\n",
        "  for x in results:\n",
        "    Data.append([name, x[0], round(x[1],2), round(x[2],2),\n",
        "                 round(x[3],2), round(x[4],2)])\n",
        "# res = res.append(dic, ignore_index=True)\n",
        "  res = pd.DataFrame(data = Data, columns = colnames)\n",
        "\n",
        "  return res"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EE2k11tpBIo"
      },
      "source": [
        "# Simulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5pygfZf0mBG"
      },
      "source": [
        "# for each of stocks, you need to put the stock code in Stock variable.\n",
        "# 'AMD', 'DVN', .... \n",
        "Stock = 'AMD'\n",
        "dfs = pd.read_csv('Dataset/' + Stock +'.csv', parse_dates=['<DATE>'])\n",
        "dfs = dfs.dropna()\n",
        "# Calculate signal to noise\n",
        "#s2n = signal_to_noise(dfs['<CLOSE>'])\n",
        "#print(f'Signal to noise = {s2n}')\n",
        "\n",
        "# Find best k\n",
        "#k = find_k(s2n)\n",
        "#print(f'best k is {k}\\n')\n",
        "\n",
        "# Denoise prices\n",
        "# denoiseMethod takes two values 'knn' for K-Nearest Neighbor denosing technique and 'ewm' for\n",
        "# Exponentially Weighted Moving Average method.\n",
        "denoiseMethod = 'ewm'\n",
        "# value takes different numbers based on denosing method. if denoiseMethod is 'knn' then\n",
        "# value comes from [12, 20, 26, 50, 70] and if denoiseMethod is 'ewm' then the value takes\n",
        "# a value from [12, 20, 26, 50]\n",
        "value = 12\n",
        "# the following line shoule be uncommented if denoiseMethod is 'knn'\n",
        "#dfs = denoise_data(dfs, '<CLOSE>', k=value)\n",
        "# the following line should be uncommented if denoiseMethod is 'ewm'\n",
        "dfs = denoise_data_EWMA(dfs, '<CLOSE>', span=value)\n",
        "dfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYM7BP0b0mBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421ee420-52e5-434f-c80f-310339ccc861"
      },
      "source": [
        "# To make sure training and test phases are properly done, we need to provide their end points\n",
        "# split_percentage is used to split the whole dataset into two desired train and test parts.\n",
        "# \n",
        "beta = 44\n",
        "split_percentatge = 0.7\n",
        "nrow = dfs.shape[0]\n",
        "train_end =round(nrow * split_percentatge) - beta\n",
        "test_end = nrow - beta\n",
        "print ('train_end = %d and test_end=%d' %(train_end, test_end))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_end = 1893 and test_end=2723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdmqBa080mBG"
      },
      "source": [
        "visualize(dfs, '<D_CLOSE>', '<DATE>', 0.05, 100, 2720)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmTLqEQAqB06"
      },
      "source": [
        "df = pd.read_csv('Dataset/' + Stock +'.csv', parse_dates=['<DATE>'])\n",
        "df = df.dropna()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_7_f2j30mBG"
      },
      "source": [
        "### Cross"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCjJw3jg0mBG"
      },
      "source": [
        "col_name = '<CLOSE>'\n",
        "Name = Stock+denoiseMethod+str(value)\n",
        "threshholds = [0.05, 0.1]\n",
        "Result_cross = pd.DataFrame()\n",
        "Result_purging = pd.DataFrame()\n",
        "for th in threshholds:\n",
        "  print('Threshhold = ', th)\n",
        "  true_label = labeling(dfs[col_name], th)\n",
        "  dfs = dfs.assign(true_labels=pd.Series(true_label).values)\n",
        "  historical = Train_data(dfs[col_name], train_start=beta+1, train_end=train_end, test_end=test_end)\n",
        "  historical.K_fold_purged(num_split=10, num_test=2, time_gaps=10, purging=False)\n",
        "  historical.set_threshold(th=th)\n",
        "  result = final_result(historical, Name, step_sizes=4, th= th)\n",
        "  Result_cross = Result_cross.append(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liG-GeHB0mBH"
      },
      "source": [
        "\n",
        "Path = 'Results/'+Stock+'/'\n",
        "Result_cross.to_csv(Path+Name+'_classification_metrics_cross.csv')\n",
        "Result_cross"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEn_NCtv2xRv"
      },
      "source": [
        "print(train_end)\n",
        "print(test_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPsles4_DXY"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNwlYMMA0mBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245eca79-e51f-4912-9fca-cc72821f6f13"
      },
      "source": [
        "# Save predictions \n",
        "\n",
        "\n",
        "# 11 days\n",
        "start = train_end + 10\n",
        "end = test_end\n",
        "print(end - start)\n",
        "print(end)\n",
        "# LSTM\n",
        "pred = historical.LSTM_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_lstm.csv')\n",
        "# GRU\n",
        "pred = historical.GRU_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_gru.csv')\n",
        "# SVM\n",
        "pred = historical.SVM_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_svm.csv')\n",
        "# XGBoost\n",
        "pred = historical.XGboost_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_xgboost.csv')\n",
        "# Logreg\n",
        "pred = historical.Logreg_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_logreg.csv')\n",
        "\n",
        "\n",
        "# 44 days\n",
        "start = train_end + 43\n",
        "end = test_end\n",
        "# LSTM\n",
        "pred = historical.LSTM_beta_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_lstm_beta.csv')\n",
        "# GRU\n",
        "pred = historical.GRU_beta_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_gru_beta.csv')\n",
        "# SVM\n",
        "pred = historical.SVM_beta_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_svm_beta.csv')\n",
        "# XGBoost\n",
        "pred = historical.XGboost_beta_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_xgboost_beta.csv')\n",
        "# Logreg\n",
        "pred = historical.Logreg_beta_predict\n",
        "new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "new_dfs.to_csv(Path+Name+'_logreg_beta.csv')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "820\n",
            "2723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpoCLnC3nNIV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCi6cZW20mBH"
      },
      "source": [
        "###Purging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BottBZG0mBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96b600c8-ea4d-4f82-dfad-202d36ffb6f2"
      },
      "source": [
        "# Note that you need to create a folder with the same name of the Stock\n",
        "# under the simulation process, i.e., if you are trying to run the code for AMD, \n",
        "# you are required to have a folder with the same name, AMD, under the 'Results'\n",
        "# folder created within the main folder, i.e., Labeling.\n",
        "Stock = 'STX'\n",
        "threshholds = [0.1]\n",
        "Path = 'Results/' + Stock + '/'\n",
        "methods = ['LSTM', 'GRU', 'XGboost', 'Logreg', 'SVM']\n",
        "denoiseMethods = ['ewm', 'knn']\n",
        "values = [12, 20, 26, 50]\n",
        "days = 44\n",
        "split_percentatge = 0.7\n",
        "\n",
        "df = pd.read_csv('Dataset/' + Stock +'.csv', parse_dates=['<DATE>'])\n",
        "df = df.dropna()\n",
        "for denoise in denoiseMethods:\n",
        "  for value in values:\n",
        "    dfs = df.copy()\n",
        "    if denoise == 'knn':\n",
        "      dfs = denoise_data(dfs, '<CLOSE>', k=value)\n",
        "    else:\n",
        "      dfs = denoise_data_EWMA(dfs, '<CLOSE>', span=value)\n",
        "    nrow = dfs.shape[0]\n",
        "    train_end =round(nrow * split_percentatge) - days\n",
        "    test_end = nrow - days\n",
        "\n",
        "    Name = Stock+denoise+str(value)\n",
        "    for th in threshholds:\n",
        "        print('Threshhold = ', th)\n",
        "        true_label = labeling(dfs[col_name], th)\n",
        "        dfs = dfs.assign(true_labels=pd.Series(true_label).values)\n",
        "        historical = Train_data(dfs[col_name], train_start=beta + 1, train_end=train_end, test_end=test_end)\n",
        "        historical.K_fold_purged(num_split=10, num_test=2, time_gaps=10, purging=True, emb=10)\n",
        "        historical.set_threshold(th=th)\n",
        "        result = final_result(historical, Name, step_sizes=4, th= th)\n",
        "        Result_purging = Result_purging.append(result)\n",
        "\n",
        "    Result_purging.to_csv(Path+Name+'_Result_purging.csv')\n",
        "        #Result_purging\n",
        "        \n",
        "    start = train_end + 10\n",
        "    end = test_end\n",
        "    save_pred(start=start, end=end, methods = methods, Path=Path, Name = Name)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 21ms/step - loss: 0.6726 - accuracy: 0.6052 - val_loss: 0.6559 - val_accuracy: 0.6280\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 13ms/step - loss: 0.5825 - accuracy: 0.7047 - val_loss: 0.5844 - val_accuracy: 0.6951\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 1s 13ms/step - loss: 0.5554 - accuracy: 0.7243 - val_loss: 0.5732 - val_accuracy: 0.7427\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 13ms/step - loss: 0.5464 - accuracy: 0.7423 - val_loss: 0.5627 - val_accuracy: 0.7378\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 13ms/step - loss: 0.5343 - accuracy: 0.7433 - val_loss: 0.5477 - val_accuracy: 0.7366\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 28ms/step - loss: 0.6198 - accuracy: 0.6504 - val_loss: 0.5500 - val_accuracy: 0.7427\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5150 - accuracy: 0.7548 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5040 - accuracy: 0.7526 - val_loss: 0.5356 - val_accuracy: 0.7390\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.4918 - accuracy: 0.7765 - val_loss: 0.5619 - val_accuracy: 0.7341\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.4836 - accuracy: 0.7765 - val_loss: 0.5702 - val_accuracy: 0.7280\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 22ms/step - loss: 0.6720 - accuracy: 0.6130 - val_loss: 0.6475 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.6534 - accuracy: 0.6213 - val_loss: 0.6078 - val_accuracy: 0.6442\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5906 - accuracy: 0.6866 - val_loss: 0.5721 - val_accuracy: 0.7154\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5476 - accuracy: 0.7265 - val_loss: 0.5472 - val_accuracy: 0.7065\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5175 - accuracy: 0.7497 - val_loss: 0.4849 - val_accuracy: 0.7764\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 23ms/step - loss: 0.6417 - accuracy: 0.6312 - val_loss: 0.5623 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5716 - accuracy: 0.7121 - val_loss: 0.5302 - val_accuracy: 0.7332\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5416 - accuracy: 0.7564 - val_loss: 0.5584 - val_accuracy: 0.7243\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4979 - accuracy: 0.7663 - val_loss: 0.5249 - val_accuracy: 0.7408\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4891 - accuracy: 0.7702 - val_loss: 0.5909 - val_accuracy: 0.7014\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.74       0.74    0.87      0.80\n",
            "1           GRU 0.1      0.73       0.73    0.89      0.80\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.78       0.81    0.85      0.83\n",
            "6      GRU beta 0.1      0.70       0.78    0.74      0.76\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 21ms/step - loss: 0.6286 - accuracy: 0.6482 - val_loss: 0.5764 - val_accuracy: 0.7244\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 13ms/step - loss: 0.5605 - accuracy: 0.7259 - val_loss: 0.5766 - val_accuracy: 0.7098\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 14ms/step - loss: 0.5389 - accuracy: 0.7439 - val_loss: 0.5645 - val_accuracy: 0.7195\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 14ms/step - loss: 0.5451 - accuracy: 0.7428 - val_loss: 0.5587 - val_accuracy: 0.7268\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 13ms/step - loss: 0.5179 - accuracy: 0.7656 - val_loss: 0.5673 - val_accuracy: 0.7073\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 28ms/step - loss: 0.6167 - accuracy: 0.6520 - val_loss: 0.5554 - val_accuracy: 0.7378\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5198 - accuracy: 0.7466 - val_loss: 0.5791 - val_accuracy: 0.6988\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5064 - accuracy: 0.7618 - val_loss: 0.5321 - val_accuracy: 0.7415\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.4932 - accuracy: 0.7684 - val_loss: 0.5323 - val_accuracy: 0.7341\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.4829 - accuracy: 0.7738 - val_loss: 0.5596 - val_accuracy: 0.7183\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 21ms/step - loss: 0.6697 - accuracy: 0.6091 - val_loss: 0.6531 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.6417 - accuracy: 0.6240 - val_loss: 0.5922 - val_accuracy: 0.7382\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5643 - accuracy: 0.7121 - val_loss: 0.5181 - val_accuracy: 0.7700\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5186 - accuracy: 0.7503 - val_loss: 0.5389 - val_accuracy: 0.7230\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.4912 - accuracy: 0.7697 - val_loss: 0.4940 - val_accuracy: 0.7776\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 23ms/step - loss: 0.6486 - accuracy: 0.6174 - val_loss: 0.5580 - val_accuracy: 0.7624\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5625 - accuracy: 0.7215 - val_loss: 0.5350 - val_accuracy: 0.7382\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5209 - accuracy: 0.7453 - val_loss: 0.5350 - val_accuracy: 0.7357\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5001 - accuracy: 0.7735 - val_loss: 0.5244 - val_accuracy: 0.7395\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4828 - accuracy: 0.7852 - val_loss: 0.5280 - val_accuracy: 0.7382\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.71       0.70    0.92      0.79\n",
            "1           GRU 0.1      0.72       0.78    0.74      0.76\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.78       0.81    0.85      0.83\n",
            "6      GRU beta 0.1      0.74       0.80    0.79      0.79\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 21ms/step - loss: 0.6371 - accuracy: 0.6422 - val_loss: 0.5822 - val_accuracy: 0.7207\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5747 - accuracy: 0.7232 - val_loss: 0.5762 - val_accuracy: 0.7220\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5601 - accuracy: 0.7336 - val_loss: 0.5670 - val_accuracy: 0.7110\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5326 - accuracy: 0.7499 - val_loss: 0.5521 - val_accuracy: 0.7415\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 14ms/step - loss: 0.5051 - accuracy: 0.7722 - val_loss: 0.5386 - val_accuracy: 0.7341\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 23ms/step - loss: 0.6009 - accuracy: 0.6639 - val_loss: 0.5480 - val_accuracy: 0.7366\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5195 - accuracy: 0.7548 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5031 - accuracy: 0.7662 - val_loss: 0.5305 - val_accuracy: 0.7415\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4938 - accuracy: 0.7602 - val_loss: 0.5585 - val_accuracy: 0.7220\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4917 - accuracy: 0.7694 - val_loss: 0.5515 - val_accuracy: 0.7402\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 22ms/step - loss: 0.6716 - accuracy: 0.6096 - val_loss: 0.6451 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.6356 - accuracy: 0.6296 - val_loss: 0.5983 - val_accuracy: 0.6836\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5666 - accuracy: 0.7215 - val_loss: 0.5535 - val_accuracy: 0.7446\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5290 - accuracy: 0.7409 - val_loss: 0.5286 - val_accuracy: 0.7306\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.4987 - val_accuracy: 0.7637\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 23ms/step - loss: 0.6566 - accuracy: 0.6035 - val_loss: 0.5801 - val_accuracy: 0.7243\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5733 - accuracy: 0.7016 - val_loss: 0.5266 - val_accuracy: 0.7700\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5142 - accuracy: 0.7630 - val_loss: 0.5005 - val_accuracy: 0.7726\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4956 - accuracy: 0.7735 - val_loss: 0.5470 - val_accuracy: 0.7281\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4854 - accuracy: 0.7802 - val_loss: 0.4945 - val_accuracy: 0.7687\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.73       0.78    0.78      0.78\n",
            "1           GRU 0.1      0.74       0.79    0.79      0.79\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.76       0.83    0.79      0.81\n",
            "6      GRU beta 0.1      0.77       0.81    0.84      0.82\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 23ms/step - loss: 0.6349 - accuracy: 0.6395 - val_loss: 0.6008 - val_accuracy: 0.7000\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5601 - accuracy: 0.7265 - val_loss: 0.5757 - val_accuracy: 0.7122\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5534 - accuracy: 0.7363 - val_loss: 0.5613 - val_accuracy: 0.7207\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5372 - accuracy: 0.7504 - val_loss: 0.5580 - val_accuracy: 0.7207\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5201 - accuracy: 0.7580 - val_loss: 0.5749 - val_accuracy: 0.7000\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 8s 25ms/step - loss: 0.6334 - accuracy: 0.6547 - val_loss: 0.5719 - val_accuracy: 0.7244\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.5135 - accuracy: 0.7482 - val_loss: 0.5383 - val_accuracy: 0.7354\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4996 - accuracy: 0.7645 - val_loss: 0.5304 - val_accuracy: 0.7415\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4843 - accuracy: 0.7787 - val_loss: 0.5328 - val_accuracy: 0.7366\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4837 - accuracy: 0.7787 - val_loss: 0.5419 - val_accuracy: 0.7415\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 23ms/step - loss: 0.6733 - accuracy: 0.6118 - val_loss: 0.6572 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.6497 - accuracy: 0.6307 - val_loss: 0.6220 - val_accuracy: 0.6925\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5873 - accuracy: 0.7076 - val_loss: 0.5702 - val_accuracy: 0.7319\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5471 - accuracy: 0.7375 - val_loss: 0.4902 - val_accuracy: 0.7700\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5115 - accuracy: 0.7458 - val_loss: 0.5036 - val_accuracy: 0.7611\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 24ms/step - loss: 0.6544 - accuracy: 0.6135 - val_loss: 0.6132 - val_accuracy: 0.7687\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5637 - accuracy: 0.7259 - val_loss: 0.5238 - val_accuracy: 0.7611\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5238 - accuracy: 0.7564 - val_loss: 0.5197 - val_accuracy: 0.7471\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5007 - accuracy: 0.7658 - val_loss: 0.4792 - val_accuracy: 0.7776\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4906 - accuracy: 0.7669 - val_loss: 0.5049 - val_accuracy: 0.7459\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.70       0.81    0.67      0.73\n",
            "1           GRU 0.1      0.74       0.78    0.81      0.79\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.76       0.83    0.78      0.81\n",
            "6      GRU beta 0.1      0.75       0.77    0.86      0.81\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 22ms/step - loss: 0.6287 - accuracy: 0.6531 - val_loss: 0.5852 - val_accuracy: 0.7146\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5753 - accuracy: 0.7064 - val_loss: 0.5838 - val_accuracy: 0.7146\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5588 - accuracy: 0.7439 - val_loss: 0.5658 - val_accuracy: 0.7146\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 14ms/step - loss: 0.5530 - accuracy: 0.7461 - val_loss: 0.5680 - val_accuracy: 0.7207\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5498 - accuracy: 0.7439 - val_loss: 0.5680 - val_accuracy: 0.7256\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 29ms/step - loss: 0.6207 - accuracy: 0.6520 - val_loss: 0.5563 - val_accuracy: 0.7293\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5116 - accuracy: 0.7602 - val_loss: 0.5363 - val_accuracy: 0.7378\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5034 - accuracy: 0.7591 - val_loss: 0.5396 - val_accuracy: 0.7366\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.4881 - accuracy: 0.7727 - val_loss: 0.5311 - val_accuracy: 0.7402\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4824 - accuracy: 0.7825 - val_loss: 0.5385 - val_accuracy: 0.7341\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 23ms/step - loss: 0.6697 - accuracy: 0.6052 - val_loss: 0.6553 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.6486 - accuracy: 0.6229 - val_loss: 0.5982 - val_accuracy: 0.6480\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.5884 - accuracy: 0.6844 - val_loss: 0.5454 - val_accuracy: 0.7370\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5304 - accuracy: 0.7414 - val_loss: 0.5030 - val_accuracy: 0.7611\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5044 - accuracy: 0.7597 - val_loss: 0.5148 - val_accuracy: 0.7471\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 25ms/step - loss: 0.6555 - accuracy: 0.6202 - val_loss: 0.5907 - val_accuracy: 0.6429\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5578 - accuracy: 0.7276 - val_loss: 0.5403 - val_accuracy: 0.7306\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5222 - accuracy: 0.7652 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4917 - accuracy: 0.7669 - val_loss: 0.5334 - val_accuracy: 0.7306\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4890 - accuracy: 0.7746 - val_loss: 0.4986 - val_accuracy: 0.7675\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.73       0.76    0.80      0.78\n",
            "1           GRU 0.1      0.73       0.77    0.80      0.79\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.75       0.80    0.81      0.80\n",
            "6      GRU beta 0.1      0.77       0.81    0.83      0.82\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 23ms/step - loss: 0.6471 - accuracy: 0.6378 - val_loss: 0.5926 - val_accuracy: 0.7073\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5802 - accuracy: 0.7102 - val_loss: 0.5912 - val_accuracy: 0.7146\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5560 - accuracy: 0.7352 - val_loss: 0.5999 - val_accuracy: 0.6854\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5494 - accuracy: 0.7471 - val_loss: 0.5634 - val_accuracy: 0.7280\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5416 - accuracy: 0.7406 - val_loss: 0.5608 - val_accuracy: 0.7402\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 6s 24ms/step - loss: 0.6428 - accuracy: 0.6319 - val_loss: 0.5624 - val_accuracy: 0.7341\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5339 - accuracy: 0.7439 - val_loss: 0.5333 - val_accuracy: 0.7427\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5061 - accuracy: 0.7656 - val_loss: 0.5380 - val_accuracy: 0.7256\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.4974 - accuracy: 0.7640 - val_loss: 0.5495 - val_accuracy: 0.7451\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.4895 - accuracy: 0.7792 - val_loss: 0.5415 - val_accuracy: 0.7305\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 23ms/step - loss: 0.6714 - accuracy: 0.6035 - val_loss: 0.6402 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.6445 - accuracy: 0.6351 - val_loss: 0.5997 - val_accuracy: 0.6989\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5804 - accuracy: 0.6993 - val_loss: 0.5762 - val_accuracy: 0.7205\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5260 - accuracy: 0.7508 - val_loss: 0.5109 - val_accuracy: 0.7611\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.4924 - accuracy: 0.7614 - val_loss: 0.5097 - val_accuracy: 0.7662\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 24ms/step - loss: 0.6535 - accuracy: 0.6213 - val_loss: 0.5933 - val_accuracy: 0.7065\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5619 - accuracy: 0.7159 - val_loss: 0.5094 - val_accuracy: 0.7726\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5202 - accuracy: 0.7591 - val_loss: 0.5212 - val_accuracy: 0.7484\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5167 - accuracy: 0.7597 - val_loss: 0.4927 - val_accuracy: 0.7662\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4971 - accuracy: 0.7547 - val_loss: 0.5470 - val_accuracy: 0.7255\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.74       0.75    0.87      0.80\n",
            "1           GRU 0.1      0.73       0.78    0.77      0.78\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.77       0.79    0.86      0.82\n",
            "6      GRU beta 0.1      0.73       0.81    0.75      0.78\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 23ms/step - loss: 0.6515 - accuracy: 0.6324 - val_loss: 0.6108 - val_accuracy: 0.6963\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5795 - accuracy: 0.7134 - val_loss: 0.5933 - val_accuracy: 0.7085\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5623 - accuracy: 0.7238 - val_loss: 0.5679 - val_accuracy: 0.7195\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5475 - accuracy: 0.7346 - val_loss: 0.5608 - val_accuracy: 0.7256\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5301 - accuracy: 0.7488 - val_loss: 0.5439 - val_accuracy: 0.7390\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 25ms/step - loss: 0.6192 - accuracy: 0.6580 - val_loss: 0.5753 - val_accuracy: 0.7134\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5267 - accuracy: 0.7504 - val_loss: 0.5888 - val_accuracy: 0.6988\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5102 - accuracy: 0.7635 - val_loss: 0.5413 - val_accuracy: 0.7354\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4927 - accuracy: 0.7749 - val_loss: 0.5443 - val_accuracy: 0.7244\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.4973 - accuracy: 0.7771 - val_loss: 0.5477 - val_accuracy: 0.7256\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 6s 24ms/step - loss: 0.6711 - accuracy: 0.6058 - val_loss: 0.6599 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6373 - accuracy: 0.6368 - val_loss: 0.6256 - val_accuracy: 0.7039\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5553 - accuracy: 0.7104 - val_loss: 0.5168 - val_accuracy: 0.7510\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5327 - accuracy: 0.7425 - val_loss: 0.5190 - val_accuracy: 0.7319\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5002 - accuracy: 0.7719 - val_loss: 0.4918 - val_accuracy: 0.7598\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 26ms/step - loss: 0.6348 - accuracy: 0.6506 - val_loss: 0.5467 - val_accuracy: 0.7446\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5756 - accuracy: 0.7132 - val_loss: 0.5301 - val_accuracy: 0.7586\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5243 - accuracy: 0.7375 - val_loss: 0.4914 - val_accuracy: 0.7814\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5148 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7713\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5056 - accuracy: 0.7636 - val_loss: 0.4794 - val_accuracy: 0.7776\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.74       0.76    0.84      0.80\n",
            "1           GRU 0.1      0.73       0.74    0.85      0.79\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.76       0.81    0.81      0.81\n",
            "6      GRU beta 0.1      0.78       0.80    0.87      0.83\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n",
            "Threshhold =  0.1\n",
            "start lstm training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 23ms/step - loss: 0.6247 - accuracy: 0.6536 - val_loss: 0.5846 - val_accuracy: 0.7220\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5644 - accuracy: 0.7314 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5526 - accuracy: 0.7433 - val_loss: 0.5834 - val_accuracy: 0.7073\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 15ms/step - loss: 0.5437 - accuracy: 0.7461 - val_loss: 0.5916 - val_accuracy: 0.6939\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 16ms/step - loss: 0.5349 - accuracy: 0.7482 - val_loss: 0.5525 - val_accuracy: 0.7390\n",
            "end training. \n",
            "\n",
            "start gru training...\n",
            "\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 7s 30ms/step - loss: 0.6096 - accuracy: 0.6667 - val_loss: 0.5485 - val_accuracy: 0.7463\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.5212 - accuracy: 0.7433 - val_loss: 0.5374 - val_accuracy: 0.7415\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4964 - accuracy: 0.7673 - val_loss: 0.5354 - val_accuracy: 0.7317\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.4985 - accuracy: 0.7727 - val_loss: 0.5422 - val_accuracy: 0.7329\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.4943 - accuracy: 0.7792 - val_loss: 0.5435 - val_accuracy: 0.7207\n",
            "end training. \n",
            "\n",
            "start xgboost training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.77711\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.794837\n",
            "[2]\tvalidation_0-auc:0.796939\n",
            "[3]\tvalidation_0-auc:0.791326\n",
            "[4]\tvalidation_0-auc:0.793035\n",
            "[5]\tvalidation_0-auc:0.794305\n",
            "[6]\tvalidation_0-auc:0.796201\n",
            "[7]\tvalidation_0-auc:0.795453\n",
            "[8]\tvalidation_0-auc:0.794026\n",
            "[9]\tvalidation_0-auc:0.793351\n",
            "[10]\tvalidation_0-auc:0.794261\n",
            "[11]\tvalidation_0-auc:0.794599\n",
            "[12]\tvalidation_0-auc:0.796207\n",
            "[13]\tvalidation_0-auc:0.796582\n",
            "[14]\tvalidation_0-auc:0.79728\n",
            "[15]\tvalidation_0-auc:0.798078\n",
            "[16]\tvalidation_0-auc:0.797934\n",
            "[17]\tvalidation_0-auc:0.798794\n",
            "[18]\tvalidation_0-auc:0.798682\n",
            "[19]\tvalidation_0-auc:0.797718\n",
            "[20]\tvalidation_0-auc:0.797896\n",
            "[21]\tvalidation_0-auc:0.796851\n",
            "[22]\tvalidation_0-auc:0.797524\n",
            "[23]\tvalidation_0-auc:0.797724\n",
            "[24]\tvalidation_0-auc:0.798269\n",
            "[25]\tvalidation_0-auc:0.799195\n",
            "[26]\tvalidation_0-auc:0.799317\n",
            "[27]\tvalidation_0-auc:0.799251\n",
            "[28]\tvalidation_0-auc:0.798682\n",
            "[29]\tvalidation_0-auc:0.798\n",
            "[30]\tvalidation_0-auc:0.798575\n",
            "[31]\tvalidation_0-auc:0.798419\n",
            "[32]\tvalidation_0-auc:0.799082\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "[34]\tvalidation_0-auc:0.799558\n",
            "[35]\tvalidation_0-auc:0.799088\n",
            "[36]\tvalidation_0-auc:0.79907\n",
            "[37]\tvalidation_0-auc:0.799038\n",
            "[38]\tvalidation_0-auc:0.798819\n",
            "[39]\tvalidation_0-auc:0.798269\n",
            "[40]\tvalidation_0-auc:0.798231\n",
            "[41]\tvalidation_0-auc:0.798413\n",
            "[42]\tvalidation_0-auc:0.798175\n",
            "[43]\tvalidation_0-auc:0.798488\n",
            "[44]\tvalidation_0-auc:0.798632\n",
            "[45]\tvalidation_0-auc:0.79865\n",
            "[46]\tvalidation_0-auc:0.797996\n",
            "[47]\tvalidation_0-auc:0.798544\n",
            "[48]\tvalidation_0-auc:0.798688\n",
            "[49]\tvalidation_0-auc:0.798894\n",
            "[50]\tvalidation_0-auc:0.798275\n",
            "[51]\tvalidation_0-auc:0.798\n",
            "[52]\tvalidation_0-auc:0.797668\n",
            "[53]\tvalidation_0-auc:0.797843\n",
            "[54]\tvalidation_0-auc:0.797887\n",
            "[55]\tvalidation_0-auc:0.797571\n",
            "[56]\tvalidation_0-auc:0.797558\n",
            "[57]\tvalidation_0-auc:0.797189\n",
            "[58]\tvalidation_0-auc:0.79683\n",
            "[59]\tvalidation_0-auc:0.797386\n",
            "[60]\tvalidation_0-auc:0.796551\n",
            "[61]\tvalidation_0-auc:0.796019\n",
            "[62]\tvalidation_0-auc:0.796051\n",
            "[63]\tvalidation_0-auc:0.796019\n",
            "[64]\tvalidation_0-auc:0.795838\n",
            "[65]\tvalidation_0-auc:0.796307\n",
            "[66]\tvalidation_0-auc:0.796007\n",
            "[67]\tvalidation_0-auc:0.795975\n",
            "[68]\tvalidation_0-auc:0.795469\n",
            "[69]\tvalidation_0-auc:0.794987\n",
            "[70]\tvalidation_0-auc:0.795118\n",
            "[71]\tvalidation_0-auc:0.795112\n",
            "[72]\tvalidation_0-auc:0.794599\n",
            "[73]\tvalidation_0-auc:0.794799\n",
            "[74]\tvalidation_0-auc:0.795143\n",
            "[75]\tvalidation_0-auc:0.795337\n",
            "[76]\tvalidation_0-auc:0.795368\n",
            "[77]\tvalidation_0-auc:0.795093\n",
            "[78]\tvalidation_0-auc:0.79479\n",
            "[79]\tvalidation_0-auc:0.794768\n",
            "[80]\tvalidation_0-auc:0.794505\n",
            "[81]\tvalidation_0-auc:0.794737\n",
            "[82]\tvalidation_0-auc:0.794405\n",
            "[83]\tvalidation_0-auc:0.794217\n",
            "Stopping. Best iteration:\n",
            "[33]\tvalidation_0-auc:0.799702\n",
            "\n",
            "end training. \n",
            "\n",
            "start lstm beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 24ms/step - loss: 0.6713 - accuracy: 0.6107 - val_loss: 0.6477 - val_accuracy: 0.6366\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6433 - accuracy: 0.6296 - val_loss: 0.6259 - val_accuracy: 0.6671\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5724 - accuracy: 0.7171 - val_loss: 0.5320 - val_accuracy: 0.7637\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5429 - accuracy: 0.7464 - val_loss: 0.5453 - val_accuracy: 0.7255\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.5137 - accuracy: 0.7614 - val_loss: 0.4941 - val_accuracy: 0.7789\n",
            "end training. \n",
            "\n",
            "start gru beta training...\n",
            "\n",
            "Epoch 1/5\n",
            "113/113 [==============================] - 7s 25ms/step - loss: 0.6594 - accuracy: 0.6118 - val_loss: 0.5997 - val_accuracy: 0.6569\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5662 - accuracy: 0.7243 - val_loss: 0.5252 - val_accuracy: 0.7510\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5194 - accuracy: 0.7553 - val_loss: 0.5055 - val_accuracy: 0.7611\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4964 - accuracy: 0.7580 - val_loss: 0.5103 - val_accuracy: 0.7560\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4893 - accuracy: 0.7757 - val_loss: 0.4848 - val_accuracy: 0.7776\n",
            "end training. \n",
            "\n",
            "start xgboost beta training...\n",
            "\n",
            "[0]\tvalidation_0-auc:0.735341\n",
            "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-auc:0.752366\n",
            "[2]\tvalidation_0-auc:0.758455\n",
            "[3]\tvalidation_0-auc:0.770504\n",
            "[4]\tvalidation_0-auc:0.778663\n",
            "[5]\tvalidation_0-auc:0.777142\n",
            "[6]\tvalidation_0-auc:0.783318\n",
            "[7]\tvalidation_0-auc:0.788535\n",
            "[8]\tvalidation_0-auc:0.793647\n",
            "[9]\tvalidation_0-auc:0.79818\n",
            "[10]\tvalidation_0-auc:0.800249\n",
            "[11]\tvalidation_0-auc:0.800703\n",
            "[12]\tvalidation_0-auc:0.804841\n",
            "[13]\tvalidation_0-auc:0.802587\n",
            "[14]\tvalidation_0-auc:0.801373\n",
            "[15]\tvalidation_0-auc:0.801994\n",
            "[16]\tvalidation_0-auc:0.803861\n",
            "[17]\tvalidation_0-auc:0.803425\n",
            "[18]\tvalidation_0-auc:0.803634\n",
            "[19]\tvalidation_0-auc:0.806359\n",
            "[20]\tvalidation_0-auc:0.804915\n",
            "[21]\tvalidation_0-auc:0.807022\n",
            "[22]\tvalidation_0-auc:0.806038\n",
            "[23]\tvalidation_0-auc:0.805417\n",
            "[24]\tvalidation_0-auc:0.807909\n",
            "[25]\tvalidation_0-auc:0.809367\n",
            "[26]\tvalidation_0-auc:0.810358\n",
            "[27]\tvalidation_0-auc:0.810023\n",
            "[28]\tvalidation_0-auc:0.811077\n",
            "[29]\tvalidation_0-auc:0.810993\n",
            "[30]\tvalidation_0-auc:0.81033\n",
            "[31]\tvalidation_0-auc:0.810306\n",
            "[32]\tvalidation_0-auc:0.81002\n",
            "[33]\tvalidation_0-auc:0.811262\n",
            "[34]\tvalidation_0-auc:0.810201\n",
            "[35]\tvalidation_0-auc:0.809995\n",
            "[36]\tvalidation_0-auc:0.80994\n",
            "[37]\tvalidation_0-auc:0.809472\n",
            "[38]\tvalidation_0-auc:0.810798\n",
            "[39]\tvalidation_0-auc:0.81188\n",
            "[40]\tvalidation_0-auc:0.811252\n",
            "[41]\tvalidation_0-auc:0.810976\n",
            "[42]\tvalidation_0-auc:0.810435\n",
            "[43]\tvalidation_0-auc:0.810365\n",
            "[44]\tvalidation_0-auc:0.810641\n",
            "[45]\tvalidation_0-auc:0.810934\n",
            "[46]\tvalidation_0-auc:0.809692\n",
            "[47]\tvalidation_0-auc:0.810376\n",
            "[48]\tvalidation_0-auc:0.810634\n",
            "[49]\tvalidation_0-auc:0.811775\n",
            "[50]\tvalidation_0-auc:0.811873\n",
            "[51]\tvalidation_0-auc:0.811991\n",
            "[52]\tvalidation_0-auc:0.81264\n",
            "[53]\tvalidation_0-auc:0.812613\n",
            "[54]\tvalidation_0-auc:0.811897\n",
            "[55]\tvalidation_0-auc:0.81159\n",
            "[56]\tvalidation_0-auc:0.810351\n",
            "[57]\tvalidation_0-auc:0.810959\n",
            "[58]\tvalidation_0-auc:0.810868\n",
            "[59]\tvalidation_0-auc:0.810069\n",
            "[60]\tvalidation_0-auc:0.810285\n",
            "[61]\tvalidation_0-auc:0.809468\n",
            "[62]\tvalidation_0-auc:0.810606\n",
            "[63]\tvalidation_0-auc:0.810952\n",
            "[64]\tvalidation_0-auc:0.811091\n",
            "[65]\tvalidation_0-auc:0.811035\n",
            "[66]\tvalidation_0-auc:0.810749\n",
            "[67]\tvalidation_0-auc:0.810742\n",
            "[68]\tvalidation_0-auc:0.811175\n",
            "[69]\tvalidation_0-auc:0.810529\n",
            "[70]\tvalidation_0-auc:0.810592\n",
            "[71]\tvalidation_0-auc:0.810746\n",
            "[72]\tvalidation_0-auc:0.81099\n",
            "[73]\tvalidation_0-auc:0.811227\n",
            "[74]\tvalidation_0-auc:0.810871\n",
            "[75]\tvalidation_0-auc:0.811737\n",
            "[76]\tvalidation_0-auc:0.811813\n",
            "[77]\tvalidation_0-auc:0.811946\n",
            "[78]\tvalidation_0-auc:0.811409\n",
            "[79]\tvalidation_0-auc:0.811248\n",
            "[80]\tvalidation_0-auc:0.811339\n",
            "[81]\tvalidation_0-auc:0.812351\n",
            "[82]\tvalidation_0-auc:0.812784\n",
            "[83]\tvalidation_0-auc:0.811576\n",
            "[84]\tvalidation_0-auc:0.811297\n",
            "[85]\tvalidation_0-auc:0.811269\n",
            "[86]\tvalidation_0-auc:0.811095\n",
            "[87]\tvalidation_0-auc:0.812302\n",
            "[88]\tvalidation_0-auc:0.812292\n",
            "[89]\tvalidation_0-auc:0.812333\n",
            "[90]\tvalidation_0-auc:0.812326\n",
            "[91]\tvalidation_0-auc:0.812682\n",
            "[92]\tvalidation_0-auc:0.812487\n",
            "[93]\tvalidation_0-auc:0.811754\n",
            "[94]\tvalidation_0-auc:0.811991\n",
            "[95]\tvalidation_0-auc:0.812396\n",
            "[96]\tvalidation_0-auc:0.811803\n",
            "[97]\tvalidation_0-auc:0.812368\n",
            "[98]\tvalidation_0-auc:0.812717\n",
            "[99]\tvalidation_0-auc:0.81271\n",
            "end training. \n",
            "\n",
            "              Model  Accuracy  Precision  Recall  F1 score\n",
            "0          LSTM 0.1      0.74       0.78    0.79      0.79\n",
            "1           GRU 0.1      0.72       0.72    0.89      0.80\n",
            "2       XGBoost 0.1      0.74       0.78    0.81      0.79\n",
            "3        Logreg 0.1      0.74       0.76    0.86      0.80\n",
            "4           SVM 0.1      0.74       0.77    0.82      0.79\n",
            "5     LSTM beta 0.1      0.78       0.82    0.84      0.83\n",
            "6      GRU beta 0.1      0.78       0.80    0.86      0.83\n",
            "7  XGBoost beta 0.1      0.74       0.79    0.80      0.80\n",
            "8   logreg beta 0.1      0.75       0.78    0.84      0.81\n",
            "9      svm beta 0.1      0.77       0.83    0.81      0.82\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEXbNBdX0mBH"
      },
      "source": [
        "# Save predictions \n",
        "def save_pred(start, end, methods, Path, Name):\n",
        "  # LSTM    \n",
        "    beta = ['','_beta']\n",
        "    for b in beta:\n",
        "      if b !='':\n",
        "        start = train_end + 43\n",
        "      for method in methods:\n",
        "        XX = method + b + '_predict'\n",
        "        X = getattr(historical, XX)\n",
        "        pred = X\n",
        "        new_dfs = dfs[start:end].assign(labels=pd.Series(pred).values)\n",
        "        filename = Path + Name + '_' + method.lower() + b + '_p.csv'\n",
        "        new_dfs.to_csv(filename)        "
      ],
      "execution_count": 86,
      "outputs": []
    }
  ]
}